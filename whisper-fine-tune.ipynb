{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:26:31.761811Z","iopub.execute_input":"2025-12-13T09:26:31.762052Z","iopub.status.idle":"2025-12-13T09:26:34.276536Z","shell.execute_reply.started":"2025-12-13T09:26:31.762035Z","shell.execute_reply":"2025-12-13T09:26:34.275948Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n  print('Not connected to a GPU')\nelse:\n  print(gpu_info)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:26:34.278604Z","iopub.execute_input":"2025-12-13T09:26:34.278974Z","iopub.status.idle":"2025-12-13T09:26:34.341928Z","shell.execute_reply.started":"2025-12-13T09:26:34.278954Z","shell.execute_reply":"2025-12-13T09:26:34.341293Z"}},"outputs":[{"name":"stdout","text":"Sat Dec 13 09:26:34 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   31C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q \\\n  torchcodec \\\n  datasets==2.18.0 \\\n  transformers==4.40.2 \\\n  accelerate==0.31.0 \\\n  peft==0.11.1 \\\n  evaluate==0.4.1 \\\n  jiwer==3.0.3 \\\n  protobuf==4.25.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:26:34.342535Z","iopub.execute_input":"2025-12-13T09:26:34.342705Z","iopub.status.idle":"2025-12-13T09:28:14.317506Z","shell.execute_reply.started":"2025-12-13T09:26:34.342691Z","shell.execute_reply":"2025-12-13T09:28:14.316758Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.3 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2024.2.0 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.25.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.3 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import datasets, pyarrow, torch\nprint(\"datasets:\", datasets.__version__)\nprint(\"pyarrow:\", pyarrow.__version__)\nprint(\"torch:\", torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:28:14.318519Z","iopub.execute_input":"2025-12-13T09:28:14.318779Z","iopub.status.idle":"2025-12-13T09:28:19.958204Z","shell.execute_reply.started":"2025-12-13T09:28:14.318745Z","shell.execute_reply":"2025-12-13T09:28:19.957410Z"}},"outputs":[{"name":"stdout","text":"datasets: 2.18.0\npyarrow: 19.0.1\ntorch: 2.6.0+cu124\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:28:19.958867Z","iopub.execute_input":"2025-12-13T09:28:19.959324Z","iopub.status.idle":"2025-12-13T09:28:20.305876Z","shell.execute_reply.started":"2025-12-13T09:28:19.959299Z","shell.execute_reply":"2025-12-13T09:28:20.305334Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n\ncv_hi = load_dataset(\"regisss/common_voice_11_0_hi\")\ncommon_voice = DatasetDict({\n    \"train\": cv_hi[\"train\"],\n    \"validation\": cv_hi[\"validation\"],\n    \"test\": cv_hi[\"test\"]\n})\n\nextra_train = load_dataset(\n    \"damerajee/Hindi-audio-speech\",\n    split=\"train\"\n)\n\nprint(common_voice)\nprint(extra_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:28:20.306614Z","iopub.execute_input":"2025-12-13T09:28:20.306853Z","iopub.status.idle":"2025-12-13T09:30:46.860825Z","shell.execute_reply.started":"2025-12-13T09:28:20.306827Z","shell.execute_reply":"2025-12-13T09:30:46.860087Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda648ffbb4341938960f98cd87758f8"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 110M/110M [00:02<00:00, 42.8MB/s] \nDownloading data: 100%|██████████| 60.2M/60.2M [00:01<00:00, 32.8MB/s]\nDownloading data: 100%|██████████| 89.2M/89.2M [00:02<00:00, 44.3MB/s]\nDownloading data: 100%|██████████| 110M/110M [00:02<00:00, 47.3MB/s] \nDownloading data: 100%|██████████| 22.6M/22.6M [00:00<00:00, 34.8MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4361 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82daf8675cf04b4e80f3d77cc1380367"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2179 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58cc484186db4624b736b27f1a930085"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2894 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a09778ca45b04bd8aa43da346645e0e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating other split:   0%|          | 0/3328 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b384523b1a4a49b5a5ad9bbb301b5168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating invalidated split:   0%|          | 0/680 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f22a33b205348db9b10542f3a93c055"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/479 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c58e6e801564ba3bdd7ec2f7486ca7c"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 667M/667M [00:33<00:00, 20.0MB/s] \nDownloading data: 100%|██████████| 659M/659M [00:12<00:00, 52.6MB/s] \nDownloading data: 100%|██████████| 659M/659M [00:12<00:00, 51.5MB/s] \nDownloading data: 100%|██████████| 634M/634M [00:12<00:00, 49.2MB/s] \nDownloading data: 100%|██████████| 683M/683M [00:28<00:00, 24.0MB/s] \nDownloading data: 100%|██████████| 655M/655M [00:12<00:00, 52.9MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2463 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e35032b7bdb42b19e690f4d33d8c2c0"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n        num_rows: 4361\n    })\n    validation: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n        num_rows: 2179\n    })\n    test: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n        num_rows: 2894\n    })\n})\nDataset({\n    features: ['audio_id', 'language', 'audio', 'raw_text', 'gender'],\n    num_rows: 2463\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"cv_train = common_voice[\"train\"].select_columns([\"audio\", \"sentence\"])\ncv_val   = common_voice[\"validation\"].select_columns([\"audio\", \"sentence\"])\ncv_test  = common_voice[\"test\"].select_columns([\"audio\", \"sentence\"])\n\n\ncv_train = cv_train.cast_column(\"audio\", Audio(sampling_rate=16000))\ncv_val   = cv_val.cast_column(\"audio\", Audio(sampling_rate=16000))\ncv_test  = cv_test.cast_column(\"audio\", Audio(sampling_rate=16000))\n\ncv_train_full = concatenate_datasets([cv_train, cv_val])\n\n\nextra_train_clean = (\n    extra_train\n    .select_columns([\"audio\", \"raw_text\"])\n    .rename_column(\"raw_text\", \"sentence\")\n    .cast_column(\"audio\", Audio(sampling_rate=16000))\n)\n\ndataset = DatasetDict({\n    \"train\": concatenate_datasets([cv_train_full, extra_train_clean]),\n    #\"train\": cv_train_full,\n    \"test\": cv_test\n})\n\nprint(dataset)\nprint(dataset[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:30:46.863334Z","iopub.execute_input":"2025-12-13T09:30:46.863762Z","iopub.status.idle":"2025-12-13T09:31:05.104399Z","shell.execute_reply.started":"2025-12-13T09:30:46.863742Z","shell.execute_reply":"2025-12-13T09:31:05.103757Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'sentence'],\n        num_rows: 9003\n    })\n    test: Dataset({\n        features: ['audio', 'sentence'],\n        num_rows: 2894\n    })\n})\n{'audio': {'path': 'common_voice_hi_26008353.mp3', 'array': array([ 3.81639165e-17,  2.42861287e-17, -1.73472348e-17, ...,\n       -1.30981789e-07,  2.63096808e-07,  4.77157300e-08]), 'sampling_rate': 16000}, 'sentence': 'हमने उसका जन्मदिन मनाया।'}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import WhisperFeatureExtractor\n\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:31:05.105061Z","iopub.execute_input":"2025-12-13T09:31:05.105551Z","iopub.status.idle":"2025-12-13T09:31:08.864331Z","shell.execute_reply.started":"2025-12-13T09:31:05.105529Z","shell.execute_reply":"2025-12-13T09:31:08.863690Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2a70e7ce124017bc2d4bd2eaaab332"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import WhisperTokenizer\n\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Hindi\", task=\"transcribe\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:31:08.865050Z","iopub.execute_input":"2025-12-13T09:31:08.865494Z","iopub.status.idle":"2025-12-13T09:31:11.480720Z","shell.execute_reply.started":"2025-12-13T09:31:08.865464Z","shell.execute_reply":"2025-12-13T09:31:11.480123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39799b97ac734bc3a57432d780bf5269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7d3588ad8514caaae0c085be5a9ca10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc378a6981340cf93189ace7f145a24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c429dafbed4ac29c76ea911692cfc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fcc2b072eb9408184d357b9e99122ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f4db58d010844ddaf622854a07b01f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9330089a892e44689a675b173344efc2"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Hindi\", task=\"transcribe\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:31:11.481455Z","iopub.execute_input":"2025-12-13T09:31:11.482012Z","iopub.status.idle":"2025-12-13T09:31:12.150970Z","shell.execute_reply.started":"2025-12-13T09:31:11.481990Z","shell.execute_reply":"2025-12-13T09:31:12.150269Z"}},"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def prepare_dataset(batch):\n    # load audio data\n    audio = batch[\"audio\"]\n\n    # compute log-Mel input features\n    batch[\"input_features\"] = processor.feature_extractor(\n        audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"]\n    ).input_features[0]\n\n    # encode target text to label ids\n    batch[\"labels\"] = processor.tokenizer(\n        batch[\"sentence\"]\n    ).input_ids\n\n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:31:12.151713Z","iopub.execute_input":"2025-12-13T09:31:12.152026Z","iopub.status.idle":"2025-12-13T09:31:12.156682Z","shell.execute_reply.started":"2025-12-13T09:31:12.151996Z","shell.execute_reply":"2025-12-13T09:31:12.156106Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.map(\n    prepare_dataset,\n    remove_columns=dataset[\"train\"].column_names,\n    num_proc=4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:31:12.157399Z","iopub.execute_input":"2025-12-13T09:31:12.157663Z","iopub.status.idle":"2025-12-13T09:35:05.563822Z","shell.execute_reply.started":"2025-12-13T09:31:12.157646Z","shell.execute_reply":"2025-12-13T09:35:05.562950Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/9003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"784dfe94e6e047d5b876d97c5e6e35b5"}},"metadata":{}},{"name":"stderr","text":"2025-12-13 09:31:15.793233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-13 09:31:15.793263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-13 09:31:15.793249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-13 09:31:15.793249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618276.212701     167 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765618276.212701     169 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618276.212719     168 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618276.212680     166 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765618276.308690     166 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1765618276.308697     167 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1765618276.308712     169 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1765618276.308712     168 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/2894 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e5360d966934e24b25a72f23708346d"}},"metadata":{}},{"name":"stderr","text":"2025-12-13 09:34:09.663031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-13 09:34:09.663128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-13 09:34:09.663667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-13 09:34:09.664683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618449.704796     200 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618449.705453     202 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618449.707664     201 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618449.708057     199 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765618449.718296     200 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1765618449.718554     202 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1765618449.721652     199 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1765618449.722779     201 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"split = dataset[\"train\"].train_test_split(\n    test_size=0.2,\n    seed=42\n)\n\ntrain_dataset = split[\"train\"]\neval_dataset  = split[\"test\"]\n\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": eval_dataset,\n    \"test\": dataset[\"test\"]\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:05.565132Z","iopub.execute_input":"2025-12-13T09:35:05.565561Z","iopub.status.idle":"2025-12-13T09:35:05.587261Z","shell.execute_reply.started":"2025-12-13T09:35:05.565523Z","shell.execute_reply":"2025-12-13T09:35:05.586677Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:05.588151Z","iopub.execute_input":"2025-12-13T09:35:05.588644Z","iopub.status.idle":"2025-12-13T09:35:21.859130Z","shell.execute_reply.started":"2025-12-13T09:35:05.588618Z","shell.execute_reply":"2025-12-13T09:35:21.858533Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d077f2602f9843228d4b8762d36bf069"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da1b23ba25b45198609e9d341392d0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9a1eb8352f40f2badbdc8c85b24d5a"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model.generation_config.language = \"hindi\"\nmodel.generation_config.task = \"transcribe\"\n\nmodel.generation_config.forced_decoder_ids = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:21.859908Z","iopub.execute_input":"2025-12-13T09:35:21.860345Z","iopub.status.idle":"2025-12-13T09:35:21.863970Z","shell.execute_reply.started":"2025-12-13T09:35:21.860325Z","shell.execute_reply":"2025-12-13T09:35:21.863253Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    decoder_start_token_id: int\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:21.864719Z","iopub.execute_input":"2025-12-13T09:35:21.864994Z","iopub.status.idle":"2025-12-13T09:35:21.948744Z","shell.execute_reply.started":"2025-12-13T09:35:21.864968Z","shell.execute_reply":"2025-12-13T09:35:21.948148Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor,\n    decoder_start_token_id=model.config.decoder_start_token_id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:21.949530Z","iopub.execute_input":"2025-12-13T09:35:21.949752Z","iopub.status.idle":"2025-12-13T09:35:21.962523Z","shell.execute_reply.started":"2025-12-13T09:35:21.949727Z","shell.execute_reply":"2025-12-13T09:35:21.962016Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"wer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:21.963153Z","iopub.execute_input":"2025-12-13T09:35:21.963387Z","iopub.status.idle":"2025-12-13T09:35:26.578313Z","shell.execute_reply.started":"2025-12-13T09:35:21.963363Z","shell.execute_reply":"2025-12-13T09:35:26.577753Z"}},"outputs":[{"name":"stderr","text":"2025-12-13 09:35:22.249143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765618522.269939      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765618522.276296      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d73a74c5826248478b057407f839d598"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_ids = pred.predictions\n    if isinstance(pred_ids, tuple):\n        pred_ids = pred_ids[0]\n\n    label_ids = pred.label_ids\n\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:26.579105Z","iopub.execute_input":"2025-12-13T09:35:26.579923Z","iopub.status.idle":"2025-12-13T09:35:26.584457Z","shell.execute_reply.started":"2025-12-13T09:35:26.579882Z","shell.execute_reply":"2025-12-13T09:35:26.583696Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"whisper-small-hi-asr\",\n    hub_model_id=\"iamgarvit/whisper-small-hi-asr\",\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n    learning_rate=1e-5,\n    warmup_steps=500,\n    max_steps=4000,\n    gradient_checkpointing=True,\n    fp16=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=1000,\n    eval_steps=1000,\n    logging_steps=25,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:26.585148Z","iopub.execute_input":"2025-12-13T09:35:26.585341Z","iopub.status.idle":"2025-12-13T09:35:27.095601Z","shell.execute_reply.started":"2025-12-13T09:35:26.585326Z","shell.execute_reply":"2025-12-13T09:35:27.095008Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"validation\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:27.096360Z","iopub.execute_input":"2025-12-13T09:35:27.096571Z","iopub.status.idle":"2025-12-13T09:35:28.935599Z","shell.execute_reply.started":"2025-12-13T09:35:27.096556Z","shell.execute_reply":"2025-12-13T09:35:28.934940Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"processor.save_pretrained(training_args.output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:28.938318Z","iopub.execute_input":"2025-12-13T09:35:28.938514Z","iopub.status.idle":"2025-12-13T09:35:29.509248Z","shell.execute_reply.started":"2025-12-13T09:35:28.938499Z","shell.execute_reply":"2025-12-13T09:35:29.508601Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T09:35:29.509932Z","iopub.execute_input":"2025-12-13T09:35:29.510150Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='31' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  31/4000 03:20 < 7:36:20, 0.14 it/s, Epoch 0.07/9]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"kwargs = {\n    \"dataset_tags\": [\"common_voice\",\"hindi\",\"speech\"],\n    \"dataset\": \"Common Voice Hindi + Hindi Audio Speech\",\n    \"dataset_args\": \"language: hi; splits: train/validation\",\n    \"language\": \"hi\",\n    \"model_name\": \"Whisper Small Hindi ASR\",\n    \"finetuned_from\": \"openai/whisper-small\",\n    \"tasks\": \"automatic-speech-recognition\",\n    \"tags\": [\"whisper\",\"asr\",\"hindi\",\"speech-recognition\",\"kaggle\"],\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub(**kwargs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\nimport gradio as gr\nimport torch\n\npipe = pipeline(\n    task=\"automatic-speech-recognition\",\n    model=\"iamgarvit/whisper-small-hi-asr\",\n    device=0 if torch.cuda.is_available() else -1,\n)\n\ndef transcribe(audio):\n    result = pipe(audio)\n    return result[\"text\"]\n\niface = gr.Interface(\n    fn=transcribe,\n    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n    outputs=\"text\",\n    title=\"Whisper Small Hindi ASR\",\n    description=\"Hindi speech recognition using a fine-tuned Whisper-small model.\",\n)\n\niface.launch()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}